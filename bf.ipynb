{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ea0dad5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "找到 5 個 xlsx 檔案在 file 1-4 中\n",
      "\n",
      "處理: E:\\EarthScienceFair_Data\\1\\G2\\1-G2-1.xlsx\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'numpy.ndarray' object has no attribute 'notna'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mAttributeError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 103\u001b[39m\n\u001b[32m     99\u001b[39m ya_raw = df.iloc[:, \u001b[32m5\u001b[39m].values\n\u001b[32m    101\u001b[39m \u001b[38;5;66;03m# 清理數據並過濾異常值\u001b[39;00m\n\u001b[32m    102\u001b[39m \u001b[38;5;66;03m# 時間數據\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m103\u001b[39m t_a = \u001b[43mclean_data_with_outlier_filter\u001b[49m\u001b[43m(\u001b[49m\u001b[43mt_a_raw\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtime_data\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[32m    104\u001b[39m t_s = clean_data_with_outlier_filter(t_s_raw, time_data=\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[32m    106\u001b[39m \u001b[38;5;66;03m# 俯瞰數據 (過濾異常值)\u001b[39;00m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 43\u001b[39m, in \u001b[36mclean_data_with_outlier_filter\u001b[39m\u001b[34m(data, time_data)\u001b[39m\n\u001b[32m     38\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m     39\u001b[39m \u001b[33;03m清理數據：移除非數值、轉換型別、並過濾異常值\u001b[39;00m\n\u001b[32m     40\u001b[39m \u001b[33;03mtime_data: 如果提供，則不對時間數據進行異常值過濾\u001b[39;00m\n\u001b[32m     41\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m     42\u001b[39m \u001b[38;5;66;03m# 移除非數值\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m43\u001b[39m data = data[\u001b[43mpd\u001b[49m\u001b[43m.\u001b[49m\u001b[43mto_numeric\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merrors\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mcoerce\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mnotna\u001b[49m()]\n\u001b[32m     44\u001b[39m data = data.astype(\u001b[38;5;28mfloat\u001b[39m)\n\u001b[32m     46\u001b[39m \u001b[38;5;66;03m# 對非時間數據進行異常值過濾\u001b[39;00m\n",
      "\u001b[31mAttributeError\u001b[39m: 'numpy.ndarray' object has no attribute 'notna'"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import glob\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import zipfile\n",
    "from scipy.fft import fft, fftfreq\n",
    "\n",
    "# Settings for file structure\n",
    "base_path = r\"E:\\EarthScienceFair_Data\"\n",
    "target_folders = [\"1\", \"2\", \"3\", \"4\"]  # 只處理 file 1-4\n",
    "\n",
    "# Mass configuration (kg) - 用 dict 對應不同組別的質量\n",
    "# Key 為組別名稱（例如 \"G1\", \"G2\"），Value 為該組的質量\n",
    "mass_dict = {\n",
    "    \"G1\": 1.8559,\n",
    "    \"G2\": 1.8600,  # 請根據實際情況修改\n",
    "    \"G3\": 1.8550,  # 請根據實際情況修改\n",
    "    \"G4\": 1.8580,  # 請根據實際情況修改\n",
    "    \"G5\": 1.8570,  # 請根據實際情況修改\n",
    "    \"G6\": 1.8590,  # 請根據實際情況修改\n",
    "    \"G7\": 1.8560,  # 請根據實際情況修改\n",
    "}\n",
    "\n",
    "# 預設質量（如果某個組別不在 dict 中）\n",
    "default_mass = 1.8559\n",
    "\n",
    "# 儲存所有實驗的原始數據，用於計算不確定度\n",
    "# 結構: {G1: {rms_x: [...], rms_y: [...], ...}, G2: {...}, ...}\n",
    "group_data = {}\n",
    "\n",
    "results = []\n",
    "\n",
    "def filter_outliers(data, threshold=0.1):\n",
    "    \"\"\"\n",
    "    過濾異常值：若前一筆數據和後一筆數據落差超過 threshold，則標記為異常\n",
    "    回傳清理後的資料索引\n",
    "    \"\"\"\n",
    "    if len(data) <= 1:\n",
    "        return np.ones(len(data), dtype=bool)\n",
    "    \n",
    "    valid_mask = np.ones(len(data), dtype=bool)\n",
    "    \n",
    "    for i in range(1, len(data)):\n",
    "        if abs(data[i] - data[i-1]) > threshold:\n",
    "            valid_mask[i] = False\n",
    "    \n",
    "    return valid_mask\n",
    "\n",
    "def clean_data_with_outlier_filter(data, time_data=None):\n",
    "    \"\"\"\n",
    "    清理數據：移除非數值、轉換型別、並過濾異常值\n",
    "    time_data: 如果提供，則不對時間數據進行異常值過濾\n",
    "    \"\"\"\n",
    "    # 移除非數值（將 numpy array 轉成 pandas Series 處理）\n",
    "    data_series = pd.Series(data)\n",
    "    data_clean = data_series[pd.to_numeric(data_series, errors='coerce').notna()].values\n",
    "    data_clean = data_clean.astype(float)\n",
    "    \n",
    "    # 對非時間數據進行異常值過濾\n",
    "    if time_data is None:\n",
    "        # 這是時間數據，只做基本清理\n",
    "        if len(data_clean) > 0:\n",
    "            data_clean = data_clean - data_clean[0]\n",
    "        return data_clean\n",
    "    else:\n",
    "        # 這是測量數據，需要過濾異常值\n",
    "        if len(data_clean) == 0:\n",
    "            return data_clean\n",
    "            \n",
    "        valid_mask = filter_outliers(data_clean, threshold=0.1)\n",
    "        data_filtered = data_clean[valid_mask]\n",
    "        \n",
    "        # 去中心化\n",
    "        if len(data_filtered) > 0:\n",
    "            data_filtered = data_filtered - np.mean(data_filtered)\n",
    "        return data_filtered\n",
    "\n",
    "# Find all xlsx files in target folders only\n",
    "xlsx_files = []\n",
    "for folder in target_folders:\n",
    "    folder_path = os.path.join(base_path, folder)\n",
    "    if os.path.exists(folder_path):\n",
    "        xlsx_files.extend(glob.glob(os.path.join(folder_path, \"**\", \"*.xlsx\"), recursive=True))\n",
    "\n",
    "print(f\"找到 {len(xlsx_files)} 個 xlsx 檔案在 file 1-4 中\\n\")\n",
    "\n",
    "for tracker_file in xlsx_files:\n",
    "    print(\"處理:\", tracker_file)\n",
    "    \n",
    "    # 提取實驗組別 (例如: \"1-G1-1.xlsx\" -> \"G1\")\n",
    "    file_name = os.path.basename(tracker_file)\n",
    "    parts = file_name.split('-')\n",
    "    if len(parts) >= 2:\n",
    "        group_name = parts[1]  # 例如 \"G1\", \"G2\"\n",
    "    else:\n",
    "        print(\"檔名格式不符，跳過\")\n",
    "        continue\n",
    "    \n",
    "    # 根據組別取得對應的質量\n",
    "    mass = mass_dict.get(group_name, default_mass)\n",
    "    print(f\"  組別: {group_name}, 質量: {mass} kg\")\n",
    "    \n",
    "    try:\n",
    "        df = pd.read_excel(tracker_file)\n",
    "    except:\n",
    "        print(\"讀取失敗:\", tracker_file)\n",
    "        continue\n",
    "\n",
    "    # 讀取資料欄位\n",
    "    # 俯瞰視角 (最後三欄)\n",
    "    t_a_raw = df.iloc[:, -3].values\n",
    "    x_raw = df.iloc[:, -2].values\n",
    "    y_raw = df.iloc[:, -1].values\n",
    "\n",
    "    # 側面視角 (前六欄)\n",
    "    t_s_raw = df.iloc[:, 0].values\n",
    "    ye_raw = df.iloc[:, 1].values\n",
    "    yd_raw = df.iloc[:, 2].values\n",
    "    yc_raw = df.iloc[:, 3].values\n",
    "    yb_raw = df.iloc[:, 4].values\n",
    "    ya_raw = df.iloc[:, 5].values\n",
    "\n",
    "    # 清理數據並過濾異常值\n",
    "    # 時間數據\n",
    "    t_a = clean_data_with_outlier_filter(t_a_raw, time_data=True)\n",
    "    t_s = clean_data_with_outlier_filter(t_s_raw, time_data=True)\n",
    "    \n",
    "    # 俯瞰數據 (過濾異常值)\n",
    "    x = clean_data_with_outlier_filter(x_raw)\n",
    "    y = clean_data_with_outlier_filter(y_raw)\n",
    "    \n",
    "    # 側面數據 (過濾異常值)\n",
    "    ye = clean_data_with_outlier_filter(ye_raw)\n",
    "    yd = clean_data_with_outlier_filter(yd_raw)\n",
    "    yc = clean_data_with_outlier_filter(yc_raw)\n",
    "    yb = clean_data_with_outlier_filter(yb_raw)\n",
    "    ya = clean_data_with_outlier_filter(ya_raw)\n",
    "\n",
    "    # 計算 RMS\n",
    "    rms_x = np.sqrt(np.mean(x**2)) if len(x) > 0 else np.nan\n",
    "    rms_y = np.sqrt(np.mean(y**2)) if len(y) > 0 else np.nan\n",
    "    ratio = rms_y / rms_x if (rms_x > 1e-8 and not np.isnan(rms_x)) else np.nan\n",
    "\n",
    "    # FFT 頻率分析\n",
    "    layers = {\n",
    "        \"ye\": ye, \"yd\": yd, \"yc\": yc, \"yb\": yb, \"ya\": ya\n",
    "    }\n",
    "    main_freqs = []\n",
    "    \n",
    "    for key, y_layer in layers.items():\n",
    "        if len(y_layer) == 0 or len(t_s) == 0:\n",
    "            continue\n",
    "            \n",
    "        min_len = min(len(t_s), len(y_layer))\n",
    "        t_temp = t_s[:min_len]\n",
    "        y_temp = y_layer[:min_len]\n",
    "        \n",
    "        if len(t_temp) < 2:\n",
    "            continue\n",
    "            \n",
    "        dt = np.mean(np.diff(t_temp))\n",
    "        if dt <= 0:\n",
    "            continue\n",
    "            \n",
    "        N = len(y_temp)\n",
    "        yf = fft(y_temp)\n",
    "        xf = fftfreq(N, dt)\n",
    "        xf = xf[:N//2]\n",
    "        amplitude = 2.0/N * np.abs(yf[:N//2])\n",
    "        \n",
    "        if len(amplitude) > 1:\n",
    "            peak_index = np.argmax(amplitude[1:]) + 1\n",
    "            main_freq = xf[peak_index]\n",
    "            print(f\"  {key} 主頻率: {main_freq:.2f} Hz\")\n",
    "            main_freqs.append(main_freq)\n",
    "    \n",
    "    if len(main_freqs) > 0:\n",
    "        f_n = np.mean(main_freqs)\n",
    "        print(f\"  系統自然頻率: {f_n:.2f} Hz\")\n",
    "    else:\n",
    "        f_n = np.nan\n",
    "        print(\"  無法計算頻率\")\n",
    "\n",
    "    # 計算剛性\n",
    "    if not np.isnan(f_n):\n",
    "        omega = 2 * np.pi * f_n\n",
    "        k = mass * omega**2\n",
    "    else:\n",
    "        k = np.nan\n",
    "\n",
    "    # 讀取加速度資料\n",
    "    folder = os.path.dirname(tracker_file)\n",
    "    base_name = os.path.splitext(os.path.basename(tracker_file))[0]\n",
    "    \n",
    "    all_zips = glob.glob(os.path.join(folder, \"*.zip\"))\n",
    "    zip_file = None\n",
    "    \n",
    "    for z in all_zips:\n",
    "        if os.path.splitext(os.path.basename(z))[0] == base_name:\n",
    "            zip_file = z\n",
    "            break\n",
    "    \n",
    "    if zip_file is not None:\n",
    "        try:\n",
    "            with zipfile.ZipFile(zip_file, 'r') as z:\n",
    "                csv_files = [f for f in z.namelist() if f.endswith('.csv')]\n",
    "                \n",
    "                if len(csv_files) > 0:\n",
    "                    with z.open(csv_files[0]) as f:\n",
    "                        acc_df = pd.read_csv(f, sep=',')\n",
    "                        acc_abs_raw = acc_df.iloc[:, -1].values\n",
    "                        \n",
    "                        # 清理加速度數據並過濾異常值\n",
    "                        acc_abs = acc_abs_raw[pd.to_numeric(acc_abs_raw, errors='coerce').notna()]\n",
    "                        acc_abs = acc_abs.astype(float)\n",
    "                        \n",
    "                        # 過濾異常值\n",
    "                        valid_mask = filter_outliers(acc_abs, threshold=0.1)\n",
    "                        acc_abs_filtered = acc_abs[valid_mask]\n",
    "                        \n",
    "                        rms_acc = np.sqrt(np.mean(acc_abs_filtered**2)) if len(acc_abs_filtered) > 0 else np.nan\n",
    "                else:\n",
    "                    rms_acc = np.nan\n",
    "        except Exception as e:\n",
    "            print(f\"  讀取 zip 檔案錯誤: {e}\")\n",
    "            rms_acc = np.nan\n",
    "    else:\n",
    "        rms_acc = np.nan\n",
    "    \n",
    "    # 儲存結果\n",
    "    results.append([tracker_file, group_name, rms_x, rms_y, ratio, f_n, k, rms_acc])\n",
    "    \n",
    "    # 將數據加入群組統計 (用於計算不確定度)\n",
    "    if group_name not in group_data:\n",
    "        group_data[group_name] = {\n",
    "            'rms_x': [], 'rms_y': [], 'ratio': [], \n",
    "            'f_n': [], 'k': [], 'rms_acc': []\n",
    "        }\n",
    "    \n",
    "    group_data[group_name]['rms_x'].append(rms_x)\n",
    "    group_data[group_name]['rms_y'].append(rms_y)\n",
    "    group_data[group_name]['ratio'].append(ratio)\n",
    "    group_data[group_name]['f_n'].append(f_n)\n",
    "    group_data[group_name]['k'].append(k)\n",
    "    group_data[group_name]['rms_acc'].append(rms_acc)\n",
    "    \n",
    "    print()\n",
    "\n",
    "# 建立結果 DataFrame\n",
    "results_df = pd.DataFrame(results, columns=[\n",
    "    \"File\", \"Group\", \"RMS_x\", \"RMS_y\", \"偏心比例\", \"主頻率(Hz)\", \"等效剛性(N/m)\", \"RMS加速度\"\n",
    "])\n",
    "\n",
    "# 計算每個群組的不確定度\n",
    "uncertainty_results = []\n",
    "\n",
    "for group_name, data in group_data.items():\n",
    "    print(f\"\\n計算 {group_name} 的不確定度:\")\n",
    "    \n",
    "    uncertainties = {}\n",
    "    \n",
    "    for param_name, values in data.items():\n",
    "        # 移除 NaN 值\n",
    "        valid_values = [v for v in values if not np.isnan(v)]\n",
    "        \n",
    "        if len(valid_values) >= 2:\n",
    "            # 計算平均值\n",
    "            mean_val = np.mean(valid_values)\n",
    "            \n",
    "            # 計算標準差 (樣本標準差，使用 n-1)\n",
    "            std_val = np.std(valid_values, ddof=1)\n",
    "            \n",
    "            # 計算標準不確定度 (u = s / sqrt(n))\n",
    "            n = len(valid_values)\n",
    "            u_val = std_val / np.sqrt(n)\n",
    "            \n",
    "            # 計算相對不確定度 (%)\n",
    "            relative_u = (u_val / mean_val * 100) if mean_val != 0 else np.nan\n",
    "            \n",
    "            uncertainties[param_name] = {\n",
    "                'mean': mean_val,\n",
    "                'std': std_val,\n",
    "                'u': u_val,\n",
    "                'relative_u': relative_u,\n",
    "                'n': n\n",
    "            }\n",
    "            \n",
    "            print(f\"  {param_name}:\")\n",
    "            print(f\"    平均值 = {mean_val:.6f}\")\n",
    "            print(f\"    標準差 = {std_val:.6f}\")\n",
    "            print(f\"    標準不確定度 u = {u_val:.6f}\")\n",
    "            print(f\"    相對不確定度 = {relative_u:.2f}%\")\n",
    "            print(f\"    樣本數 n = {n}\")\n",
    "        else:\n",
    "            uncertainties[param_name] = {\n",
    "                'mean': valid_values[0] if len(valid_values) == 1 else np.nan,\n",
    "                'std': np.nan,\n",
    "                'u': np.nan,\n",
    "                'relative_u': np.nan,\n",
    "                'n': len(valid_values)\n",
    "            }\n",
    "            print(f\"  {param_name}: 樣本數不足 (n={len(valid_values)})\")\n",
    "    \n",
    "    uncertainty_results.append({\n",
    "        'Group': group_name,\n",
    "        'RMS_x_mean': uncertainties['rms_x']['mean'],\n",
    "        'RMS_x_u': uncertainties['rms_x']['u'],\n",
    "        'RMS_y_mean': uncertainties['rms_y']['mean'],\n",
    "        'RMS_y_u': uncertainties['rms_y']['u'],\n",
    "        'ratio_mean': uncertainties['ratio']['mean'],\n",
    "        'ratio_u': uncertainties['ratio']['u'],\n",
    "        'f_n_mean': uncertainties['f_n']['mean'],\n",
    "        'f_n_u': uncertainties['f_n']['u'],\n",
    "        'k_mean': uncertainties['k']['mean'],\n",
    "        'k_u': uncertainties['k']['u'],\n",
    "        'rms_acc_mean': uncertainties['rms_acc']['mean'],\n",
    "        'rms_acc_u': uncertainties['rms_acc']['u'],\n",
    "        'sample_size': uncertainties['rms_x']['n']\n",
    "    })\n",
    "\n",
    "uncertainty_df = pd.DataFrame(uncertainty_results)\n",
    "\n",
    "# 輸出結果\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"File 1-4 分析結果:\")\n",
    "print(\"=\"*80)\n",
    "print(results_df)\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"各組不確定度統計:\")\n",
    "print(\"=\"*80)\n",
    "print(uncertainty_df)\n",
    "\n",
    "# 存檔\n",
    "results_df.to_csv(\"analysis_results_file1to4.csv\", index=False, encoding='utf-8-sig')\n",
    "uncertainty_df.to_csv(\"uncertainty_file1to4.csv\", index=False, encoding='utf-8-sig')\n",
    "\n",
    "print(\"\\n結果已儲存至:\")\n",
    "print(\"  - analysis_results_file1to4.csv (詳細結果)\")\n",
    "print(\"  - uncertainty_file1to4.csv (不確定度統計)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83067e63",
   "metadata": {},
   "source": [
    "Above code were provided by Claude and fixed by human."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
